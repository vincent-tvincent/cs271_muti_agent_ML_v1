{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "from SwarmEnvironment import *\n",
    "from SwarmAgent import *\n",
    "import numpy\n",
    "# ------------------------------\n",
    "# 4. Training Loop\n",
    "# ------------------------------\n",
    "load_model = True\n",
    "numpy.random.seed(20)\n",
    "manual_selected_device = torch.device(\"cuda\")\n",
    "\n",
    "n_agents = 20\n",
    "space_size = 20\n",
    "visible_neighbor_amount = 4\n",
    "error_tolerance = 0.5 # to goal\n",
    "collision_tolerance = 0.25\n",
    "linear_displacement = 0.125\n",
    "angular_displacement = 22.5\n",
    "\n",
    "env = SwarmEnv(n_agents=n_agents, space_size=space_size, linear_displacement=linear_displacement, angular_displacement=angular_displacement, visible_neighbor_amount=visible_neighbor_amount)\n",
    "env.set_random_goals()\n",
    "agent = Agent(state_dim=env.observation_dimension, action_dim=env.action_amount, device=manual_selected_device)\n",
    "if load_model:\n",
    "    agent.model.load_state_dict(torch.load(\"swarm_agent_model.pth\"))\n",
    "    agent.target.load_state_dict(torch.load(\"swarm_target_model.pth\"))\n",
    "print(env.action_amount)\n",
    "\n",
    "\n",
    "agent.gamma = 0.9 # q learning gamma, learning rate\n",
    "agent.epsilon = 1.0 # action randomness 1 for fully random\n",
    "agent.batch_size = 128\n",
    "\n",
    "training_steps = 1000\n",
    "episodes_length = 516\n",
    "\n",
    "epsilon_decay = 0.999 # action randomness decay rate\n",
    "epsilon_decay_accelerating_factor = 0.99\n",
    "epsilon_min = 0.05 # minimum epsilon\n",
    "\n",
    "env.non_goal_reward = -1.0\n",
    "env.goal_reward = 50.0\n",
    "env.collision_reward = -2.0\n",
    "env.distance_reward_factor = 5.0 / linear_displacement # how much nearest neighbor evey agent can visit\n",
    "\n",
    "total_rewards = np.zeros(training_steps)\n",
    "epsilons = np.zeros(training_steps)\n",
    "time_spend = np.zeros(training_steps)\n",
    "\n",
    "for episode in range(training_steps):\n",
    "    observations = env.reset()\n",
    "    env.set_random_goals()\n",
    "    total_reward = 0\n",
    "    start_time = time.time()\n",
    "    step = 0\n",
    "    for step in range(episodes_length):\n",
    "       # Batched GPU/MPS inference for all agents\n",
    "       actions = agent.select_multiple_actions(observations)  # replaces the for-loop\n",
    "\n",
    "        # Environment step (expects actions as a list or array)\n",
    "       next_observations, rewards, done, _ = env.step(actions, error_tolerance=error_tolerance, collision_tolerance=collision_tolerance)\n",
    "\n",
    "       # Store transitions for all agents\n",
    "       for i in range(env.n_agents):\n",
    "           agent.store(observations[i], actions[i], rewards[i], next_observations[i])\n",
    "\n",
    "       # Train DQN\n",
    "       agent.train_step()\n",
    "\n",
    "       # Move to next step\n",
    "       observations = next_observations\n",
    "       total_reward += np.mean(rewards)\n",
    "\n",
    "       # End early if environment finishes\n",
    "       if done:\n",
    "           agent.train_step(done)\n",
    "           break\n",
    "\n",
    "    agent.update_target()\n",
    "    # agent.epsilon = max(epsilon_min, agent.epsilon * epsilon_decay)\n",
    "\n",
    "    delta_time = time.time() - start_time\n",
    "\n",
    "    total_rewards[episode] = total_reward\n",
    "    epsilons[episode] = agent.epsilon\n",
    "    time_spend[episode] = delta_time\n",
    "    print(f\"Episode {episode + 1}, steps {step + 1:.0f} (done: {env.done_count/n_agents * 100.0:.3f}% collision: {env.collision_count:.0f}), Average total reward {total_reward:.5f}, epsilon {agent.epsilon:.5f} time {delta_time:.5f}s\")\n",
    "\n",
    "    agent.epsilon_decay(epsilon_min, epsilon_decay)\n",
    "\n",
    "# Save model weights\n",
    "torch.save(agent.model.state_dict(), \"swarm_agent_model.pth\")\n",
    "torch.save(agent.target.state_dict(), \"swarm_target_model.pth\")\n"
   ],
   "id": "9a05d03740482d55",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def visualize_swarm(agent, env, steps=50, save=False, interval=10):\n",
    "    \"\"\"\n",
    "    Visualize swarm movement in 3D and optionally save 4 views as .gif.\n",
    "    - Agents that are 'done' are shown in green from that step onward.\n",
    "    - save=False → live animation (in Jupyter)\n",
    "    - save=True  → export 4 gifs: normal, xy, xz, yz\n",
    "    \"\"\"\n",
    "    obs = env.reset()\n",
    "    positions_history = [env.positions.copy()]\n",
    "    done_history = []\n",
    "\n",
    "    print(\"stepping\")\n",
    "    done_flags = np.zeros(env.num_agents, dtype=bool)\n",
    "\n",
    "    for _ in range(steps):\n",
    "        actions = agent.select_multiple_actions(obs)\n",
    "        obs, _, done, _ = env.step(actions, error_tolerance=error_tolerance)\n",
    "\n",
    "        # Support both scalar and per-agent done\n",
    "        if np.isscalar(done):\n",
    "            done_flags[:] = done\n",
    "        else:\n",
    "            done_flags |= np.array(done)  # once done → always done\n",
    "\n",
    "        done_history.append(done_flags.copy())\n",
    "        positions_history.append(env.positions.copy())\n",
    "\n",
    "        if np.all(done_flags):\n",
    "            break\n",
    "\n",
    "    print(\"plotting\")\n",
    "\n",
    "    positions_history = np.array(positions_history)  # [T, n_agents, 3]\n",
    "    done_history = np.array(done_history)            # [T, n_agents]\n",
    "    n_steps, n_agents, _ = positions_history.shape\n",
    "\n",
    "    goals = np.atleast_2d(env.goal)\n",
    "    if goals.shape[0] == 1:\n",
    "        goals = np.repeat(goals, n_agents, axis=0)\n",
    "\n",
    "    # ----------------------------\n",
    "    # Helper to make and save GIFs\n",
    "    # ----------------------------\n",
    "    def make_animation(view_name, elev, azim):\n",
    "        fig = plt.figure(figsize=(6, 6))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.set_xlim(0, env.space_size)\n",
    "        ax.set_ylim(0, env.space_size)\n",
    "        ax.set_zlim(0, env.space_size)\n",
    "        ax.set_xlabel(\"X-axis\")\n",
    "        ax.set_ylabel(\"Y-axis\")\n",
    "        ax.set_zlabel(\"Z-axis\")\n",
    "        ax.set_title(f\"3D Swarm Movement ({view_name})\")\n",
    "\n",
    "        # Initial scatter\n",
    "        scat = ax.scatter([], [], [], c='blue', s=50, label='Agents')\n",
    "        ax.scatter(goals[:,0], goals[:,1], goals[:,2],\n",
    "                   c='red', s=100, marker='*', label='Goals')\n",
    "\n",
    "        lines = [ax.plot([], [], [], 'gray', linestyle='--', linewidth=1)[0]\n",
    "                 for _ in range(n_agents)]\n",
    "\n",
    "        ax.view_init(elev=elev, azim=azim)\n",
    "        ax.legend()\n",
    "\n",
    "        def init():\n",
    "            scat._offsets3d = ([], [], [])\n",
    "            return [scat, *lines]\n",
    "\n",
    "        def update(frame):\n",
    "            pos = positions_history[frame]\n",
    "            done_flags = done_history[min(frame, done_history.shape[0]-1)]\n",
    "            colors = ['green' if d else 'blue' for d in done_flags]\n",
    "            scat._offsets3d = (pos[:,0], pos[:,1], pos[:,2])\n",
    "            scat.set_color(colors)\n",
    "\n",
    "            for i, line in enumerate(lines):\n",
    "                x = [pos[i, 0], goals[i, 0]]\n",
    "                y = [pos[i, 1], goals[i, 1]]\n",
    "                z = [pos[i, 2], goals[i, 2]]\n",
    "                line.set_data(x, y)\n",
    "                line.set_3d_properties(z)\n",
    "\n",
    "            ax.set_title(f\"3D Swarm Movement ({view_name}) - Step {frame}/{n_steps}\")\n",
    "            return [scat, *lines]\n",
    "\n",
    "        ani = animation.FuncAnimation(\n",
    "            fig, update, frames=n_steps, init_func=init,\n",
    "            interval=interval, blit=False\n",
    "        )\n",
    "\n",
    "        if save:\n",
    "            filename = f\"swarm_simulation_{view_name.lower()}.gif\"\n",
    "            ani.save(filename, writer='pillow')\n",
    "            print(f\"✅ Saved {filename}\")\n",
    "        else:\n",
    "            plt.show()\n",
    "\n",
    "        plt.close(fig)\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # A) SAVE FOUR VIEWS AS GIFS\n",
    "    # ------------------------------------------------\n",
    "    if save:\n",
    "        make_animation(\"normal\", elev=30, azim=45)\n",
    "        make_animation(\"xy\", elev=90, azim=-90)\n",
    "        make_animation(\"xz\", elev=0, azim=-90)\n",
    "        make_animation(\"yz\", elev=0, azim=0)\n",
    "        return\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # B) LIVE DISPLAY (REAL-TIME UPDATE in Jupyter)\n",
    "    # ------------------------------------------------\n",
    "    plt.ion()\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.set_xlim(0, env.space_size)\n",
    "    ax.set_ylim(0, env.space_size)\n",
    "    ax.set_zlim(0, env.space_size)\n",
    "    ax.set_title(\"3D Swarm Movement (Live)\")\n",
    "    scat = ax.scatter([], [], [], c='blue', s=50, label='Agents')\n",
    "    ax.scatter(goals[:,0], goals[:,1], goals[:,2],\n",
    "               c='red', s=100, marker='*', label='Goals')\n",
    "    lines = [ax.plot([], [], [], 'gray', linestyle='--', linewidth=1)[0]\n",
    "             for _ in range(n_agents)]\n",
    "    ax.legend()\n",
    "\n",
    "    for frame in range(n_steps):\n",
    "        pos = positions_history[frame]\n",
    "        done_flags = done_history[min(frame, done_history.shape[0]-1)]\n",
    "        colors = ['green' if d else 'blue' for d in done_flags]\n",
    "        scat._offsets3d = (pos[:,0], pos[:,1], pos[:,2])\n",
    "        scat.set_color(colors)\n",
    "\n",
    "        for i, line in enumerate(lines):\n",
    "            x = [pos[i, 0], goals[i, 0]]\n",
    "            y = [pos[i, 1], goals[i, 1]]\n",
    "            z = [pos[i, 2], goals[i, 2]]\n",
    "            line.set_data(x, y)\n",
    "            line.set_3d_properties(z)\n",
    "\n",
    "        ax.set_title(f\"3D Swarm Movement (Live) - Step {frame}/{n_steps}\")\n",
    "        display(fig)\n",
    "        clear_output(wait=True)\n",
    "        plt.pause(interval / 1000.0)\n",
    "\n",
    "    plt.ioff()\n",
    "    plt.show()\n"
   ],
   "id": "10b1709892c840c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "  visualize_swarm(agent, env, steps=600, save=True)",
   "id": "b54bb0e99d5b5c01",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
