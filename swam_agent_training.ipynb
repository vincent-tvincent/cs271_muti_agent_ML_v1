{
 "cells": [
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-11-10T21:26:30.523549Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "\n",
    "from SwarmEnvironment import *\n",
    "from SwarmAgent import *\n",
    "import numpy\n",
    "# ------------------------------\n",
    "# 4. Training Loop\n",
    "# ------------------------------\n",
    "numpy.random.seed(20)\n",
    "manual_selected_device = \"cuda\"\n",
    "\n",
    "n_agents = 20\n",
    "visible_neighbor_amount = 3\n",
    "error_tolerance = 0.1\n",
    "# collision_error_tolerance = 0.5\n",
    "\n",
    "env = SwarmEnv(n_agents=n_agents, space_size=50, linear_displacement=1.0, visible_neighbor_amount=visible_neighbor_amount)\n",
    "env.set_random_goals()\n",
    "agent = Agent(state_dim=env.observation_dimension, action_dim=env.action_amount, device=manual_selected_device)\n",
    "print(env.action_amount)\n",
    "\n",
    "\n",
    "agent.gamma = 0.7 # q learning gamma, learning rate\n",
    "agent.epsilon = 1.0 # action randomness 1 for fully random\n",
    "agent.batch_size = 128\n",
    "\n",
    "training_steps = 1000\n",
    "episodes_length = 512\n",
    "\n",
    "epsilon_decay = 0.999 # action randomness decay rate\n",
    "epsilon_min = 0.05 # minimum epsilon\n",
    "\n",
    "env.non_goal_reward = -5.0\n",
    "env.goal_reward = 10\n",
    "env.collision_reward = -20.0\n",
    "env.distance_reward_factor = 1.0 # how much nearest neighbor evey agent can visit\n",
    "\n",
    "for episode in range(training_steps):\n",
    "    observations = env.reset()\n",
    "    total_reward = 0\n",
    "    start_time = time.time()\n",
    "    for step in range(episodes_length):\n",
    "       # Batched GPU/MPS inference for all agents\n",
    "       actions = agent.select_multiple_actions(observations)  # replaces the for-loop\n",
    "\n",
    "        # Environment step (expects actions as a list or array)\n",
    "       next_observations, rewards, done, _ = env.step(actions, error_tolerance=error_tolerance)\n",
    "\n",
    "       # Store transitions for all agents\n",
    "       for i in range(env.n_agents):\n",
    "           agent.store(observations[i], actions[i], rewards[i], next_observations[i])\n",
    "\n",
    "       # Train DQN\n",
    "       agent.train_step()\n",
    "\n",
    "       # Move to next step\n",
    "       observations = next_observations\n",
    "       total_reward += np.mean(rewards)\n",
    "\n",
    "       # End early if environment finishes\n",
    "       if done:\n",
    "           break\n",
    "\n",
    "    agent.update_target()\n",
    "    # agent.epsilon = max(epsilon_min, agent.epsilon * epsilon_decay)\n",
    "    agent.epsilon_decay(epsilon_min, epsilon_decay)\n",
    "    delta_time = time.time() - start_time\n",
    "    print(f\"Episode {episode}, Average total reward {total_reward:.5f}, epsilon {agent.epsilon:.5f} time {delta_time:.5f} s\")"
   ],
   "id": "9a05d03740482d55",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device :  cuda\n",
      "1440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bluelobster/UCI/CS271p/cs271_muti_agent_ML_v1/SwarmAgent.py:96: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)\n",
      "  s = torch.tensor(s, dtype=torch.float32, device=self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0, Average total reward -2534.75000, epsilon 0.99900 time 5.66319 s\n",
      "Episode 1, Average total reward -2533.82612, epsilon 0.99800 time 5.61440 s\n",
      "Episode 2, Average total reward -2537.40000, epsilon 0.99700 time 5.62019 s\n",
      "Episode 3, Average total reward -3484.00493, epsilon 0.99601 time 5.61631 s\n",
      "Episode 4, Average total reward -2530.18552, epsilon 0.99501 time 5.62433 s\n",
      "Episode 5, Average total reward -2536.93463, epsilon 0.99401 time 5.64026 s\n",
      "Episode 6, Average total reward -2540.01173, epsilon 0.99302 time 5.65233 s\n",
      "Episode 7, Average total reward -2530.91732, epsilon 0.99203 time 5.64759 s\n",
      "Episode 8, Average total reward -2528.75310, epsilon 0.99104 time 5.65859 s\n",
      "Episode 9, Average total reward -2530.89992, epsilon 0.99004 time 5.66453 s\n",
      "Episode 10, Average total reward -2533.72376, epsilon 0.98905 time 5.65857 s\n",
      "Episode 11, Average total reward -2530.05000, epsilon 0.98807 time 5.66333 s\n",
      "Episode 12, Average total reward -2528.26371, epsilon 0.98708 time 5.68240 s\n",
      "Episode 13, Average total reward -2518.80467, epsilon 0.98609 time 5.68486 s\n",
      "Episode 14, Average total reward -3549.15558, epsilon 0.98510 time 5.66930 s\n",
      "Episode 15, Average total reward -2517.28023, epsilon 0.98412 time 5.69094 s\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T21:05:49.014078Z",
     "start_time": "2025-11-10T21:05:48.687673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import animation\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "def visualize_swarm(agent, env, steps=50, save=False, interval=10):\n",
    "    \"\"\"\n",
    "    Visualize swarm movement in 3D and optionally save 4 views as .gif.\n",
    "    - save=False → real-time live animation (in Jupyter)\n",
    "    - save=True  → export 4 gifs: normal, xy, xz, yz\n",
    "    \"\"\"\n",
    "\n",
    "    obs = env.reset()\n",
    "    positions_history = [env.positions.copy()]\n",
    "\n",
    "    for _ in range(steps):\n",
    "        # actions = [agent.select_action(o) for o in obs]\n",
    "        actions = agent.select_multiple_actions(obs)\n",
    "        obs, _, done, _ = env.step(actions, error_tolerance=error_tolerance)\n",
    "        positions_history.append(env.positions.copy())\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    positions_history = np.array(positions_history)  # shape: [T, n_agents, 3]\n",
    "    n_steps, n_agents, _ = positions_history.shape\n",
    "\n",
    "    # Normalize goal shape\n",
    "    goals = np.atleast_2d(env.goal)\n",
    "    if goals.shape[0] == 1:\n",
    "        goals = np.repeat(goals, n_agents, axis=0)\n",
    "\n",
    "    # ----------------------------\n",
    "    # Helper to make and save GIFs\n",
    "    # ----------------------------\n",
    "    def make_animation(view_name, elev, azim):\n",
    "        fig = plt.figure(figsize=(6, 6))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.set_xlim(0, env.space_size)\n",
    "        ax.set_ylim(0, env.space_size)\n",
    "        ax.set_zlim(0, env.space_size)\n",
    "        ax.set_xlabel(\"X-axis\")\n",
    "        ax.set_ylabel(\"Y-axis\")\n",
    "        ax.set_zlabel(\"Z-axis\")\n",
    "        ax.set_title(f\"3D Swarm Movement ({view_name})\")\n",
    "\n",
    "        scat = ax.scatter([], [], [], c='blue', s=50, label='Agents')\n",
    "        ax.scatter(goals[:,0], goals[:,1], goals[:,2],\n",
    "                   c='red', s=100, marker='*', label='Goals')\n",
    "\n",
    "        lines = [ax.plot([], [], [], 'gray', linestyle='--', linewidth=1)[0]\n",
    "                 for _ in range(n_agents)]\n",
    "\n",
    "        ax.view_init(elev=elev, azim=azim)\n",
    "        ax.legend()\n",
    "\n",
    "        def init():\n",
    "            scat._offsets3d = ([], [], [])\n",
    "            for line in lines:\n",
    "                line.set_data([], [])\n",
    "                line.set_3d_properties([])\n",
    "            return [scat, *lines]\n",
    "\n",
    "        def update(frame):\n",
    "            pos = positions_history[frame]\n",
    "            scat._offsets3d = (pos[:,0], pos[:,1], pos[:,2])\n",
    "            for i, line in enumerate(lines):\n",
    "                x = [pos[i, 0], goals[i, 0]]\n",
    "                y = [pos[i, 1], goals[i, 1]]\n",
    "                z = [pos[i, 2], goals[i, 2]]\n",
    "                line.set_data(x, y)\n",
    "                line.set_3d_properties(z)\n",
    "            ax.set_title(f\"3D Swarm Movement ({view_name}) - Step {frame}/{n_steps}\")\n",
    "            return [scat, *lines]\n",
    "\n",
    "        ani = animation.FuncAnimation(\n",
    "            fig, update, frames=n_steps, init_func=init,\n",
    "            interval=interval, blit=False\n",
    "        )\n",
    "\n",
    "        if save:\n",
    "            filename = f\"swarm_simulation_{view_name.lower()}.gif\"\n",
    "            ani.save(filename, writer='pillow')\n",
    "            print(f\"✅ Saved {filename}\")\n",
    "        else:\n",
    "            plt.show()\n",
    "\n",
    "        plt.close(fig)\n",
    "\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # A) SAVE FOUR VIEWS AS GIFS\n",
    "    # ------------------------------------------------\n",
    "    if save:\n",
    "        make_animation(\"normal\", elev=30, azim=45)\n",
    "        make_animation(\"xy\", elev=90, azim=-90)\n",
    "        make_animation(\"xz\", elev=0, azim=-90)\n",
    "        make_animation(\"yz\", elev=0, azim=0)\n",
    "        return\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # B) LIVE DISPLAY (REAL-TIME UPDATE in Jupyter)\n",
    "    # ------------------------------------------------\n",
    "    plt.ion()  # Turn on interactive mode\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.set_xlim(0, env.space_size)\n",
    "    ax.set_ylim(0, env.space_size)\n",
    "    ax.set_zlim(0, env.space_size)\n",
    "    ax.set_title(\"3D Swarm Movement (Live)\")\n",
    "    scat = ax.scatter([], [], [], c='blue', s=50, label='Agents')\n",
    "    ax.scatter(goals[:,0], goals[:,1], goals[:,2],\n",
    "               c='red', s=100, marker='*', label='Goals')\n",
    "    lines = [ax.plot([], [], [], 'gray', linestyle='--', linewidth=1)[0]\n",
    "             for _ in range(n_agents)]\n",
    "    ax.legend()\n",
    "\n",
    "    for frame in range(n_steps):\n",
    "        pos = positions_history[frame]\n",
    "        scat._offsets3d = (pos[:,0], pos[:,1], pos[:,2])\n",
    "        for i, line in enumerate(lines):\n",
    "            x = [pos[i, 0], goals[i, 0]]\n",
    "            y = [pos[i, 1], goals[i, 1]]\n",
    "            z = [pos[i, 2], goals[i, 2]]\n",
    "            line.set_data(x, y)\n",
    "            line.set_3d_properties(z)\n",
    "        ax.set_title(f\"3D Swarm Movement (Live) - Step {frame}/{n_steps}\")\n",
    "        display(fig)\n",
    "        clear_output(wait=True)\n",
    "        plt.pause(interval / 1000.0)\n",
    "\n",
    "    plt.ioff()\n",
    "    plt.show()\n"
   ],
   "id": "10b1709892c840c",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T21:02:05.929605Z",
     "start_time": "2025-11-10T20:59:55.501567Z"
    }
   },
   "cell_type": "code",
   "source": "  visualize_swarm(agent, env, steps=500, save=True)",
   "id": "b54bb0e99d5b5c01",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved swarm_simulation_normal.gif\n",
      "✅ Saved swarm_simulation_xy.gif\n",
      "✅ Saved swarm_simulation_xz.gif\n",
      "✅ Saved swarm_simulation_yz.gif\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
