{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T11:01:05.701579Z",
     "start_time": "2025-11-09T11:01:03.956235Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "\n",
    "from SwarmEnvironment import *\n",
    "from SwarmAgent import *\n",
    "import numpy\n",
    "# ------------------------------\n",
    "# 4. Training Loop\n",
    "# ------------------------------\n",
    "numpy.random.seed(20)\n",
    "manual_selected_device = \"mps\"\n",
    "\n",
    "n_agents = 20\n",
    "visible_neighbor_amount = n_agents\n",
    "env = SwarmEnv(n_agents=n_agents, space_size=50, linear_displacement=5.0, visible_neighbor_amount=n_agents)\n",
    "env.set_random_goals()\n",
    "agent = Agent(state_dim=env.observation_dimension, action_dim=env.action_amount, device=manual_selected_device)\n",
    "print(env.action_amount)\n",
    "agent.gamma = 0.95 # q learning gamma, learning rate\n",
    "agent.epsilon = 1.0 # action randomness 1 for fully random\n",
    "agent.batch_size = 64\n",
    "\n",
    "epsilon_decay = 0.99 # action randomness decay rate\n",
    "epsilon_min = 0.05 # minimum epsilon\n",
    "\n",
    "env.goal_reward = 2.0\n",
    "env.collision_reward = -20.0\n",
    "env.distance_reward_factor = 2.0 # how much nearest neighbor evey agent can visit\n",
    "\n",
    "training_steps = 1000\n",
    "episodes_length = 500\n",
    "\n",
    "for episode in range(training_steps):\n",
    "    observations = env.reset()\n",
    "    total_reward = 0\n",
    "\n",
    "    for step in range(episodes_length):\n",
    "       # Batched GPU/MPS inference for all agents\n",
    "       actions = agent.select_multiple_actions(observations)  # replaces the for-loop\n",
    "\n",
    "        # Environment step (expects actions as a list or array)\n",
    "       next_observations, rewards, done, _ = env.step(actions)\n",
    "\n",
    "       # Store transitions for all agents\n",
    "       for i in range(env.n_agents):\n",
    "           agent.store(observations[i], actions[i], rewards[i], next_observations[i])\n",
    "\n",
    "       # Train DQN\n",
    "       agent.train_step()\n",
    "\n",
    "       # Move to next step\n",
    "       observations = next_observations\n",
    "       total_reward += np.mean(rewards)\n",
    "\n",
    "       # End early if environment finishes\n",
    "       if done:\n",
    "           break\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    agent.update_target()\n",
    "    agent.epsilon = max(epsilon_min, agent.epsilon * epsilon_decay)\n",
    "    print(f\"Episode {episode}, average total reward {total_reward:.2f}, eps {agent.epsilon:.2f}\")"
   ],
   "id": "9a05d03740482d55",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device :  mps\n",
      "720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vincentpu/Library/CloudStorage/OneDrive-个人/UCI/CS271P/Swarm_ML_v1/SwarmAgent.py:91: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:281.)\n",
      "  s = torch.tensor(s, dtype=torch.float32, device=self.device)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "linear(): input and weight.T shapes cannot be multiplied (64x63 and 36x1024)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 49\u001B[39m\n\u001B[32m     46\u001B[39m     agent.store(observations[i], actions[i], rewards[i], next_observations[i])\n\u001B[32m     48\u001B[39m \u001B[38;5;66;03m# Train DQN\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m49\u001B[39m \u001B[43magent\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtrain_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     51\u001B[39m \u001B[38;5;66;03m# Move to next step\u001B[39;00m\n\u001B[32m     52\u001B[39m observations = next_observations\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Library/CloudStorage/OneDrive-个人/UCI/CS271P/Swarm_ML_v1/SwarmAgent.py:96\u001B[39m, in \u001B[36mAgent.train_step\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m     93\u001B[39m r = torch.tensor(r, dtype=torch.float32, device=\u001B[38;5;28mself\u001B[39m.device).unsqueeze(\u001B[32m1\u001B[39m)\n\u001B[32m     94\u001B[39m s2 = torch.tensor(s2, dtype=torch.float32, device=\u001B[38;5;28mself\u001B[39m.device)\n\u001B[32m---> \u001B[39m\u001B[32m96\u001B[39m q = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m)\u001B[49m.gather(\u001B[32m1\u001B[39m, a)\n\u001B[32m     97\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m torch.no_grad():\n\u001B[32m     98\u001B[39m     q_target = r + \u001B[38;5;28mself\u001B[39m.gamma * \u001B[38;5;28mself\u001B[39m.target(s2).max(\u001B[32m1\u001B[39m, keepdim=\u001B[38;5;28;01mTrue\u001B[39;00m)[\u001B[32m0\u001B[39m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1551\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1552\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1553\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1557\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1558\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1559\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1560\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1561\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1562\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1564\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m   1565\u001B[39m     result = \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Library/CloudStorage/OneDrive-个人/UCI/CS271P/Swarm_ML_v1/SwarmAgent.py:29\u001B[39m, in \u001B[36mDQN.forward\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m     28\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[32m---> \u001B[39m\u001B[32m29\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mnet\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1551\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1552\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1553\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1557\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1558\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1559\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1560\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1561\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1562\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1564\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m   1565\u001B[39m     result = \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/container.py:219\u001B[39m, in \u001B[36mSequential.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    217\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[32m    218\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m219\u001B[39m         \u001B[38;5;28minput\u001B[39m = \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    220\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1551\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1552\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1553\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1557\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1558\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1559\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1560\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1561\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1562\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1564\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m   1565\u001B[39m     result = \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/linear.py:117\u001B[39m, in \u001B[36mLinear.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    116\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) -> Tensor:\n\u001B[32m--> \u001B[39m\u001B[32m117\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mRuntimeError\u001B[39m: linear(): input and weight.T shapes cannot be multiplied (64x63 and 36x1024)"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import animation\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "def visualize_swarm(agent, env, steps=50, save=False, interval=10):\n",
    "    \"\"\"\n",
    "    Visualize swarm movement in 3D and optionally save 4 views as .gif.\n",
    "    - save=False → real-time live animation (in Jupyter)\n",
    "    - save=True  → export 4 gifs: normal, xy, xz, yz\n",
    "    \"\"\"\n",
    "\n",
    "    obs = env.reset()\n",
    "    positions_history = [env.positions.copy()]\n",
    "\n",
    "    for _ in range(steps):\n",
    "        actions = [agent.select_action(o) for o in obs]\n",
    "        obs, _, done, _ = env.step(actions)\n",
    "        positions_history.append(env.positions.copy())\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    positions_history = np.array(positions_history)  # shape: [T, n_agents, 3]\n",
    "    n_steps, n_agents, _ = positions_history.shape\n",
    "\n",
    "    # Normalize goal shape\n",
    "    goals = np.atleast_2d(env.goal)\n",
    "    if goals.shape[0] == 1:\n",
    "        goals = np.repeat(goals, n_agents, axis=0)\n",
    "\n",
    "    # ----------------------------\n",
    "    # Helper to make and save GIFs\n",
    "    # ----------------------------\n",
    "    def make_animation(view_name, elev, azim):\n",
    "        fig = plt.figure(figsize=(6, 6))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.set_xlim(0, env.space_size)\n",
    "        ax.set_ylim(0, env.space_size)\n",
    "        ax.set_zlim(0, env.space_size)\n",
    "        ax.set_xlabel(\"X-axis\")\n",
    "        ax.set_ylabel(\"Y-axis\")\n",
    "        ax.set_zlabel(\"Z-axis\")\n",
    "        ax.set_title(f\"3D Swarm Movement ({view_name})\")\n",
    "\n",
    "        scat = ax.scatter([], [], [], c='blue', s=50, label='Agents')\n",
    "        ax.scatter(goals[:,0], goals[:,1], goals[:,2],\n",
    "                   c='red', s=100, marker='*', label='Goals')\n",
    "\n",
    "        lines = [ax.plot([], [], [], 'gray', linestyle='--', linewidth=1)[0]\n",
    "                 for _ in range(n_agents)]\n",
    "\n",
    "        ax.view_init(elev=elev, azim=azim)\n",
    "        ax.legend()\n",
    "\n",
    "        def init():\n",
    "            scat._offsets3d = ([], [], [])\n",
    "            for line in lines:\n",
    "                line.set_data([], [])\n",
    "                line.set_3d_properties([])\n",
    "            return [scat, *lines]\n",
    "\n",
    "        def update(frame):\n",
    "            pos = positions_history[frame]\n",
    "            scat._offsets3d = (pos[:,0], pos[:,1], pos[:,2])\n",
    "            for i, line in enumerate(lines):\n",
    "                x = [pos[i, 0], goals[i, 0]]\n",
    "                y = [pos[i, 1], goals[i, 1]]\n",
    "                z = [pos[i, 2], goals[i, 2]]\n",
    "                line.set_data(x, y)\n",
    "                line.set_3d_properties(z)\n",
    "            ax.set_title(f\"3D Swarm Movement ({view_name}) - Step {frame}/{n_steps}\")\n",
    "            return [scat, *lines]\n",
    "\n",
    "        ani = animation.FuncAnimation(\n",
    "            fig, update, frames=n_steps, init_func=init,\n",
    "            interval=interval, blit=False\n",
    "        )\n",
    "\n",
    "        if save:\n",
    "            filename = f\"swarm_simulation_{view_name.lower()}.gif\"\n",
    "            ani.save(filename, writer='pillow')\n",
    "            print(f\"✅ Saved {filename}\")\n",
    "        else:\n",
    "            plt.show()\n",
    "\n",
    "        plt.close(fig)\n",
    "\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # A) SAVE FOUR VIEWS AS GIFS\n",
    "    # ------------------------------------------------\n",
    "    if save:\n",
    "        make_animation(\"normal\", elev=30, azim=45)\n",
    "        make_animation(\"xy\", elev=90, azim=-90)\n",
    "        make_animation(\"xz\", elev=0, azim=-90)\n",
    "        make_animation(\"yz\", elev=0, azim=0)\n",
    "        return\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # B) LIVE DISPLAY (REAL-TIME UPDATE in Jupyter)\n",
    "    # ------------------------------------------------\n",
    "    plt.ion()  # Turn on interactive mode\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.set_xlim(0, env.space_size)\n",
    "    ax.set_ylim(0, env.space_size)\n",
    "    ax.set_zlim(0, env.space_size)\n",
    "    ax.set_title(\"3D Swarm Movement (Live)\")\n",
    "    scat = ax.scatter([], [], [], c='blue', s=50, label='Agents')\n",
    "    ax.scatter(goals[:,0], goals[:,1], goals[:,2],\n",
    "               c='red', s=100, marker='*', label='Goals')\n",
    "    lines = [ax.plot([], [], [], 'gray', linestyle='--', linewidth=1)[0]\n",
    "             for _ in range(n_agents)]\n",
    "    ax.legend()\n",
    "\n",
    "    for frame in range(n_steps):\n",
    "        pos = positions_history[frame]\n",
    "        scat._offsets3d = (pos[:,0], pos[:,1], pos[:,2])\n",
    "        for i, line in enumerate(lines):\n",
    "            x = [pos[i, 0], goals[i, 0]]\n",
    "            y = [pos[i, 1], goals[i, 1]]\n",
    "            z = [pos[i, 2], goals[i, 2]]\n",
    "            line.set_data(x, y)\n",
    "            line.set_3d_properties(z)\n",
    "        ax.set_title(f\"3D Swarm Movement (Live) - Step {frame}/{n_steps}\")\n",
    "        display(fig)\n",
    "        clear_output(wait=True)\n",
    "        plt.pause(interval / 1000.0)\n",
    "\n",
    "    plt.ioff()\n",
    "    plt.show()\n"
   ],
   "id": "10b1709892c840c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "  visualize_swarm(agent, env, steps=500, save=True)",
   "id": "b54bb0e99d5b5c01",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
